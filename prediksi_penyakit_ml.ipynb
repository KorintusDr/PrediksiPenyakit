{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Prediksi Penyakit Dengan Machine Learning"
      ],
      "metadata": {
        "id": "3A4kB3f1Pt67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library dan Dataset\n",
        "\n",
        "Pertama, saya memuat pustaka-pustaka yang diperlukan dan dataset dari file CSV menggunakan pandas. Dataset ini terdiri dari data latih dan data uji untuk melatih dan menguji model prediksi penyakit."
      ],
      "metadata": {
        "id": "7yrmBFMUP7a-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import mode\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from statistics import mode\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "H0vHlpywqtfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pemeriksaan Keseimbangan Dataset\n",
        "\n",
        "Setelah memuat dataset, langkah selanjutnya adalah memeriksa apakah dataset seimbang atau tidak. Ini dilakukan dengan memplot jumlah sampel untuk setiap penyakit yang terdaftar dalam kolom \"prognosis\"."
      ],
      "metadata": {
        "id": "IyBZCtf7r6CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca dataset dari file CSV dan menghapus kolom kosong\n",
        "DATA_PATH = \"Training.csv\"\n",
        "data = pd.read_csv(DATA_PATH).dropna(axis = 1)\n",
        "\n",
        "# Memeriksa keseimbangan dataset dengan plot bar\n",
        "disease_counts = data[\"prognosis\"].value_counts()\n",
        "temp_df = pd.DataFrame({\n",
        "    \"Disease\": disease_counts.index,\n",
        "    \"Counts\": disease_counts.values\n",
        "})\n",
        "\n",
        "plt.figure(figsize = (18,8))\n",
        "sns.barplot(x = \"Disease\", y = \"Counts\", data = temp_df)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PcCgji5qpnn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Data\n",
        "\n",
        "Setelah memastikan dataset seimbang, langkah berikutnya adalah melakukan preprocessing terhadap data. Hal ini meliputi mengubah kolom target (\"prognosis\") dari tipe string ke tipe numerik menggunakan Label Encoder, serta membagi data menjadi data latih dan data uji untuk evaluasi model."
      ],
      "metadata": {
        "id": "3nosCa7Hr9Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengubah nilai target menjadi nilai numerik menggunakan LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "data[\"prognosis\"] = encoder.fit_transform(data[\"prognosis\"])"
      ],
      "metadata": {
        "id": "w2fYUSuEq0_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Membagi dataset menjadi data latih dan data uji"
      ],
      "metadata": {
        "id": "-LuGfID0xhdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:,:-1]\n",
        "y = data.iloc[:, -1]\n",
        "X_train, X_test, y_train, y_test =train_test_split(\n",
        "  X, y, test_size = 0.2, random_state = 24)\n",
        "\n",
        "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "id": "_1wVXnQ4pvfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pembangunan Model\n",
        "\n",
        "Setelah mempersiapkan data, langkah selanjutnya adalah membangun model menggunakan tiga algoritma yang berbeda: Support Vector Classifier (SVC), Gaussian Naive Bayes Classifier, dan Random Forest Classifier. Saya menggunakan K-Fold Cross-Validation untuk mengevaluasi kinerja masing-masing model."
      ],
      "metadata": {
        "id": "qgYIm05Ksdrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan metrik penilaian untuk cross-validation k-fold\n",
        "def cv_scoring(estimator, X, y):\n",
        "    return accuracy_score(y, estimator.predict(X))\n",
        "\n",
        "# Inisialisasi Model\n",
        "models = {\n",
        "    \"SVC\":SVC(),\n",
        "    \"Gaussian NB\":GaussianNB(),\n",
        "    \"Random Forest\":RandomForestClassifier(random_state=18)\n",
        "}\n",
        "\n",
        "# Evaluasi model menggunakan K-Fold Cross-Validation\n",
        "for model_name in models:\n",
        "    model = models[model_name]\n",
        "    scores = cross_val_score(model, X, y, cv = 10,\n",
        "                             n_jobs = -1,\n",
        "                             scoring = cv_scoring)\n",
        "    print(\"==\"*30)\n",
        "    print(model_name)\n",
        "    print(f\"Scores: {scores}\")\n",
        "    print(f\"Mean Score: {np.mean(scores)}\")"
      ],
      "metadata": {
        "id": "Y581O6dHp1by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kombinasi Model dan Evaluasi\n",
        "\n",
        "Untuk membangun model yang lebih robust, saya mengkombinasikan prediksi dari ketiga model yang telah dilatih. Hal ini dilakukan dengan melatih setiap model pada data latih dan mengevaluasi kinerjanya menggunakan matriks pada data uji."
      ],
      "metadata": {
        "id": "vGCAJxuIyDVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih dan menguji SVM Classifier\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "preds = svm_model.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy on train data by SVM Classifier: {accuracy_score(y_train, svm_model.predict(X_train)) * 100}\")\n",
        "print(f\"Accuracy on test data by SVM Classifier: {accuracy_score(y_test, preds) * 100}\")\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test, preds)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.title(\"Confusion Matrix for SVM Classifier on Test Data\")\n",
        "plt.show()\n",
        "\n",
        "# Melatih dan menguji Naive Bayes Classifier\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "preds = nb_model.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy on train data by Naive Bayes Classifier: {accuracy_score(y_train, nb_model.predict(X_train)) * 100}\")\n",
        "print(f\"Accuracy on test data by Naive Bayes Classifier: {accuracy_score(y_test, preds) * 100}\")\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test, preds)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.title(\"Confusion Matrix for Naive Bayes Classifier on Test Data\")\n",
        "plt.show()\n",
        "\n",
        "# Melatih dan menguji Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=18)\n",
        "rf_model.fit(X_train, y_train)\n",
        "preds = rf_model.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy on train data by Random Forest Classifier: {accuracy_score(y_train, rf_model.predict(X_train)) * 100}\")\n",
        "print(f\"Accuracy on test data by Random Forest Classifier: {accuracy_score(y_test, preds) * 100}\")\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test, preds)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.title(\"Confusion Matrix for Random Forest Classifier on Test Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1L18PayEqA__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pengujian Pada Data Uji\n",
        "\n",
        "Setelah memastikan kinerja model yang baik pada data uji, saya menguji model kombinasi pada dataset pengujian. Hasil prediksi diperoleh dengan menggabungkan prediksi dari SVM, Naive Bayes, dan Random Forest menggunakan mode dari prediksi-prediksi tersebut."
      ],
      "metadata": {
        "id": "cp60o59Hdny9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model pada seluruh data dan memvalidasi pada dataset pengujian\n",
        "final_svm_model = SVC()\n",
        "final_nb_model = GaussianNB()\n",
        "final_rf_model = RandomForestClassifier(random_state=18)\n",
        "final_svm_model.fit(X, y)\n",
        "final_nb_model.fit(X, y)\n",
        "final_rf_model.fit(X, y)\n",
        "\n",
        "# Membaca data pengujian\n",
        "test_data = pd.read_csv(\"Testing.csv\").dropna(axis=1)\n",
        "\n",
        "test_X = test_data.iloc[:, :-1]\n",
        "test_Y = encoder.transform(test_data.iloc[:, -1])\n",
        "\n",
        "# Melakukan prediksi dengan mengambil mode dari prediksi semua klasifier\n",
        "svm_preds = final_svm_model.predict(test_X)\n",
        "nb_preds = final_nb_model.predict(test_X)\n",
        "rf_preds = final_rf_model.predict(test_X)\n",
        "\n",
        "final_preds = mode([svm_preds, nb_preds, rf_preds], axis=0)[0].flatten()\n",
        "\n",
        "print(f\"Accuracy on test data by SVM Classifier: {accuracy_score(test_Y, svm_preds) * 100}\")\n",
        "\n",
        "cf_matrix = confusion_matrix(test_Y, final_preds)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.title(\"Confusion Matrix for Final Model on Test Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_GhFObYrqKo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fungsi Prediksi\n",
        "Terakhir, saya membuat fungsi yang dapat menerima gejala-gejala yang dipisahkan oleh koma sebagai input, dan menghasilkan prediksi penyakit menggunakan model gabungan berdasarkan gejala tersebut.\n",
        "\n"
      ],
      "metadata": {
        "id": "B4SKbykahGN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symptoms = X.columns.values\n",
        "\n",
        "symptom_index = {}\n",
        "for index, value in enumerate(symptoms):\n",
        "    symptom = \" \".join([i.capitalize() for i in value.split(\"_\")])\n",
        "    symptom_index[symptom] = index\n",
        "\n",
        "data_dict = {\n",
        "    \"symptom_index\": symptom_index,\n",
        "    \"predictions_classes\": encoder.classes_\n",
        "}\n",
        "\n",
        "# Membuat fungsi untuk menghasilkan prediksi penyakit berdasarkan gejala input\n",
        "def predictDisease(symptoms):\n",
        "    symptoms = symptoms.split(\",\")\n",
        "\n",
        "    # Membuat data input untuk model\n",
        "    input_data = [0] * len(data_dict[\"symptom_index\"])\n",
        "    for symptom in symptoms:\n",
        "        symptom = symptom.strip()  # Menghapus spasi yang tidak diperlukan\n",
        "        if symptom in data_dict[\"symptom_index\"]:\n",
        "            index = data_dict[\"symptom_index\"][symptom]\n",
        "            input_data[index] = 1\n",
        "\n",
        "    # Mengubah data input menjadi DataFrame\n",
        "    input_data = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "    # Melakukan prediksi dengan masing-masing model\n",
        "    rf_prediction = data_dict[\"predictions_classes\"][final_rf_model.predict(input_data)[0]]\n",
        "    nb_prediction = data_dict[\"predictions_classes\"][final_nb_model.predict(input_data)[0]]\n",
        "    svm_prediction = data_dict[\"predictions_classes\"][final_svm_model.predict(input_data)[0]]\n",
        "\n",
        "    # Menggabungkan prediksi dengan mengambil mode dari semua prediksi\n",
        "    final_prediction = mode([rf_prediction, nb_prediction, svm_prediction])\n",
        "    predictions = {\n",
        "        \"rf_model_prediction\": rf_prediction,\n",
        "        \"naive_bayes_prediction\": nb_prediction,\n",
        "        \"svm_model_prediction\": svm_prediction,\n",
        "        \"final_prediction\": final_prediction\n",
        "    }\n",
        "    return predictions\n",
        "\n",
        "# Menguji fungsi prediksi\n",
        "print(predictDisease(\"Itching,Skin Rash,Nodal Skin Eruptions\"))"
      ],
      "metadata": {
        "id": "izuKVPSSqTon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}